{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkDQxhywcMQp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from initLayers import initLayers\n",
        "from train import train\n",
        "from rna import rna\n",
        "from utils import normalize, splitData, accuracy\n",
        "\n",
        "# Carrega dados do dataset:\n",
        "DATASET_PATH = './data/heart.csv'\n",
        "data = np.genfromtxt(DATASET_PATH, delimiter=',', skip_header=1)\n",
        "\n",
        "# Separa features e labels:\n",
        "features = data[:, :-1]\n",
        "labels = data[:, -1:]\n",
        "\n",
        "# Separa dados para treinamento e para validação:\n",
        "featuresTrain, featuresVal, labelsTrain, labelsVal = splitData(features, labels)\n",
        "\n",
        "# Normaliza features:\n",
        "normalized_features, feature_scaler = normalize(featuresTrain)\n",
        "\n",
        "# Define a estrutura da rede, funções de ativação, funções de custo, épocas e learning rate:\n",
        "# Obtém a quantidade de neurons da camada de input\n",
        "INPUT_NEURONS = len(normalized_features[0])\n",
        "\n",
        "# Define a estrutura da rede e funções de ativação\n",
        "layers = [\n",
        "    (INPUT_NEURONS, 'RELU'),\n",
        "    #(INPUT_NEURONS, 'RELU'),\n",
        "    (1, 'SIGMOID')\n",
        "]\n",
        "\n",
        "# Definição função de custo, épocas e learning rate\n",
        "COSTF = \"BINARY_ENTROPY\"\n",
        "EPOCHS = 100\n",
        "LEARNING_RATE = 0.002\n",
        "\n",
        "# Inicializa os pesos e as funções das camadas:\n",
        "layers = initLayers(layers, INPUT_NEURONS)\n",
        "\n",
        "# Dispara o treinamento da rede:\n",
        "trainedParams = train(EPOCHS, LEARNING_RATE, layers, normalized_features, labelsTrain, COSTF)\n",
        "\n",
        "# Normaliza as features para validação:\n",
        "test_normalized_features = feature_scaler.transform(featuresVal)\n",
        "\n",
        "# Testa a rede treinada:\n",
        "predictions = []\n",
        "for i, observation in enumerate(test_normalized_features):\n",
        "\n",
        "  input = observation\n",
        "  prediction = rna(input, trainedParams)\n",
        "\n",
        "  #predictions.append(one_hot_prediction)\n",
        "  predictions.append(prediction)\n",
        "\n",
        "# Obtém métricas de avaliação:\n",
        "\n",
        "accuracy = accuracy(np.round(np.array(predictions)), np.round(np.array(labelsVal)))\n",
        "print(\" accuracy: \", accuracy)"
      ]
    }
  ]
}
